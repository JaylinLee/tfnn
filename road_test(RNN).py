import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time


class DataSet(object):
    def __init__(self, path):
        # including [deri_v, dx, dv, deri_a_clipped, v_l]
        self._road_data = pd.read_pickle(path).loc[:,
                          ['Vehicle_ID', 'deri_v', 'dx', 'dv', 'deri_a_clipped', 'v_l']].dropna()
        self._car_ids = np.unique(self._road_data['Vehicle_ID'])
        self._id_index = None

    def _get_car_data(self):
        if self._new_id_index != self._id_index:
            self._id_index = self._new_id_index
            car_id = self._car_ids[self._id_index]
            self._car_data = self._road_data[self._road_data['Vehicle_ID'] == car_id]
        return self._car_data

    def next(self, batch_size, time_steps, predict='v'):
        while True:
            if not hasattr(self, '_new_id_index'):
                self._new_id_index = 0
            car_data = self._get_car_data()
            if predict == 'a':
                car_features = np.vstack((
                    car_data['deri_a_clipped'] / 3, # self acceleration
                    car_data['deri_v'] / 17 - 0.5,  # self speed
                    car_data['dv'] / 10,            # relevant speed
                    car_data['dx'] / 86 - 0.5,      # gap
                )).T
                car_targets = car_data['deri_a_clipped'].as_matrix()[:, np.newaxis]
            elif predict == 'v':
                car_features = np.vstack((
                    car_data['deri_a_clipped'] / 3,  # self acceleration
                    car_data['deri_v'] / 17 - 0.5,  # self speed
                    # car_data['v_l'] / 17 - 0.5,     # preceding speed (reduce the dependency of self speed)
                    car_data['dv'] / 10,            # relevant speed
                    car_data['dx'] / 86 - 0.5,      # gap
                )).T
                car_targets = car_data['deri_v'].as_matrix()[:, np.newaxis]
            else:
                raise ValueError
            if not hasattr(self, '_start'):
                self._start = 0
            self._end = self._start + time_steps
            if self._end < car_features.shape[0]:
                features = car_features[self._start: self._end, :][np.newaxis, :, :]    # 2_3D
                targets = car_targets[self._start + 1: self._end + 1, :][np.newaxis, :, :]      # 2_3D
                if self._start == 0:
                    is_zero_initial_state = True
                else:
                    is_zero_initial_state = False
                self._start += time_steps
                break
            else:
                self._new_id_index = self._id_index + 1
                if self._new_id_index + 1 >= len(self._car_ids):
                    self._new_id_index = 0
                self._start = 0

        return [features, targets, is_zero_initial_state]


def test(test_config, id, on_test=True, predict='a'):
    model = RNN(test_config, is_training=False)
    model.restore(test_config.restore_path + '_' + predict)
    df = pd.read_pickle(test_config.data_path)[['filter_position', 'Vehicle_ID', 'Frame_ID',
                                    'deri_v', 'deri_a_clipped']].dropna().astype(np.float32)
    df = df[df['filter_position'] < 380]
    ids = np.unique(df.Vehicle_ID)
    filter_ids = ids[ids >= id]
    ps = pd.DataFrame()
    vs = pd.DataFrame()
    accs = pd.DataFrame()
    for i, car_id in enumerate(filter_ids):
        if i > 8:
            break
        car_data = df[df['Vehicle_ID'] == car_id]
        car_data = car_data.set_index(['Frame_ID'])
        car_position = car_data['filter_position']
        car_speed = car_data['deri_v']
        car_acc = car_data['deri_a_clipped']
        # shape (time, n_car) for positions
        ps = pd.concat([ps, car_position.rename(i)], axis=1)
        # shape (time, n_car) for speeds
        vs = pd.concat([vs, car_speed.rename(i)], axis=1)
        accs = pd.concat([accs, car_acc.rename(i)], axis=1)

    test_ps = ps.copy()
    test_vs = vs.copy()
    test_accs = accs.copy()

    for i in range(1, 9):
        end_f_id = test_ps.iloc[:, i - 1].dropna().index[-1]    # for preceding vehicle
        is_initial_state = True
        for t in test_ps.iloc[:, i].dropna().index:     # for current vehicle
            if t == end_f_id:
                break
            # index from test data
            """if use the real ps and vs in here, the predicted acceleration is very close,
            but it has the accumulated error, which will result in a big change in position data.
            If use test_ps, and test_vs, which will depend on the data generated by last time (from prediction).
            the acceleration error will be greater then last method (using real data directly),
            but the position error will be less than last method."""
            if on_test:
                # depend on test
                p_data = test_ps.loc[t, i]
                v_data = test_vs.loc[t, i]
                a_data = test_accs.loc[t, i]
            else:
                # depend on real
                p_data = ps.loc[t, i]
                v_data = vs.loc[t, i]
                a_data = accs.loc[t, i]
            # keep index from real data for leader
            pl_data = ps.loc[t, i - 1]
            vl_data = vs.loc[t, i - 1]
            dx_data = pl_data - p_data
            dv_data = vl_data - v_data
            # speed, leader_speed, dx, dv
            # [furthest, nearest]
            if predict == 'a':
                # speed, relevant_speed, dx
                # [furthest, nearest]
                input_data = np.asarray(
                    [
                        a_data / 3,  # self acceleration
                        v_data / 17 - 0.5,      # self speed,
                        dv_data / 10,           # relevant speed
                        dx_data / 86 - 0.5,     # gap
                    ])[np.newaxis, np.newaxis, :]
                new_a = model.predict(input_data, is_initial_state)
                is_initial_state = False
                speed_t2 = test_vs.loc[t, i] + new_a * 0.2
                speed_t2 = 0 if speed_t2 < 0 else speed_t2

                test_accs.loc[t + 1, i] = new_a
                test_vs.loc[t + 2, i] = speed_t2
                test_ps.loc[t + 3, i] = test_ps.loc[t + 1, i] + speed_t2 * 0.2
            elif predict == 'v':
                # leader_speed, dx, dv
                # [furthest, nearest]
                input_data = np.asarray([
                    a_data / 3,  # self acceleration
                    v_data / 17 - 0.5,      # self speed
                    # vl_data / 17 - 0.5,  # preceding speed (reduce the dependency of self speed)
                    dv_data / 10,  # relevant speed
                    dx_data / 86 - 0.5,  # gap
                ])[np.newaxis, np.newaxis, :]

                new_speed = model.predict(input_data, is_initial_state)
                is_initial_state = False
                new_speed = 0 if new_speed < 0 else new_speed
                test_vs.loc[t + 1, i] = new_speed  # next speed
                test_ps.loc[t + 2, i] = test_ps.loc[t, i] + new_speed * 0.2  # next position
                if not np.isnan(test_vs.loc[t - 1, i]):
                    test_accs.loc[t, i] = (new_speed - test_vs.loc[t - 1, i]) / 0.2      # acceleration for now
            elif predict == 'delta_x':
                """
                !!!!
                bad idea
                !!!!
                """
                # speed, leader_speed, dx
                # [furthest, nearest]
                input_data = pd.concat([v_data, vl_data, dx_data])
                delta_x = model.predict(input_data)
                delta_x = 0 if delta_x < 0 else delta_x
                # delta_x = (v0+v1)*t/2
                # so v1 = delta_x*2/t - v0
                test_ps.loc[t, i] = test_ps.loc[t - 1, i] + delta_x
                test_vs.loc[t, i] = delta_x / 0.1
                test_accs.loc[t, i] = (test_vs.loc[t, i] - test_vs.loc[t - 1, i]) / 0.1

    plt.figure(0)
    plt.title('Position')
    plt.plot(ps, 'k-')
    plt.plot(test_ps.iloc[:, 1:], 'r--')
    plt.ylim((0, 400))

    f, ax = plt.subplots(8, 1)
    f.suptitle('Velocity')
    for i in range(8):
        ax[i].plot(vs.iloc[:, i + 1], 'k-')
        ax[i].plot(test_vs.iloc[:, i + 1], 'r--')

    f, ax = plt.subplots(8, 1)
    f.suptitle('Acceleration')
    for i in range(8):
        ax[i].plot(accs.iloc[:, i + 1], 'k-')
        ax[i].plot(test_accs.iloc[:, i + 1], 'r--')

    f, ax = plt.subplots(8, 1)
    f.suptitle('test real acceleration diff cumsum')
    for i in range(8):
        ax[i].plot((test_accs.iloc[:, i + 1] - accs.iloc[:, i + 1]).cumsum(), 'k-')

    plt.show()


def train(train_config, predict):
    data = DataSet(train_config.data_path)
    plotter = Plotter(train_config.time_steps, PREDICT)
    rnn = RNN(train_config, is_training=True)
    st = time.time()
    for i in range(ITER_STEPS):
        road_xs, road_ys, zero_initial_state = data.next(train_config.batch_size, train_config.time_steps,
                                                         predict=predict)

        if zero_initial_state:
            state_ = rnn.run(rnn.cell_initial_state)
        feed_dict = {rnn.xs: road_xs, rnn.ys: road_ys, rnn.cell_initial_state: state_}
        _, state_, cost_, pred_ = rnn.run([rnn.train_op, rnn.cell_final_state, rnn.cost, rnn.pred], feed_dict=feed_dict)
        plotter.append_data(pred_.flatten().tolist(), road_ys.flatten().tolist())

        if zero_initial_state:
            init_time = plotter.plt_time
            init_acc = road_ys.flatten()[0]
        if i % PLOT_LOOP == 0:
            plotter.update(init_time, init_acc)
            print(round(time.time() - st, 2), 'cost: ', cost_)
            st = time.time()
        plotter.plt_time += train_config.time_steps

    print("Save to path: ", rnn.save('tmp/rnn_{}'.format(predict)))
    plt.ioff()


class Plotter(object):
    def __init__(self, time_steps=1, which='v'):
        self._time_steps = time_steps
        plt.ion()
        self.fig, self.ax = plt.subplots(figsize=(13, 5))
        plt.show()
        if which == 'v':
            plt.ylim((-5, 20))  # 4 predicting speed
        elif which == 'a':
            plt.ylim((-3.5, 3.5))  # 4 predicting acc
        self.plt_time = 0
        self.pred_to_plot = []
        self.road_ys_to_plot = []

    def update(self, init_time, init_acc):
        if len(self.pred_to_plot) > 600:
            self.pred_to_plot = self.pred_to_plot[-600:]
            self.road_ys_to_plot = self.road_ys_to_plot[-600:]
        if not hasattr(self, 'pred_line'):
            self.init_scatter = plt.scatter([init_time], [init_acc], s=100, c='red', alpha=.5, edgecolors=None)
            self.pred_line, = plt.plot(
                np.arange(self.plt_time, self.plt_time+self._time_steps),
                self.pred_to_plot, 'b-', label='predict')
            self.road_line, = plt.plot(
                np.arange(self.plt_time, self.plt_time+self._time_steps),
                self.road_ys_to_plot, 'r-', label='real')
            plt.legend()
        else:
            self.init_scatter.set_offsets([init_time, init_acc])
            self.pred_line.set_data(
                np.arange(self.plt_time+self._time_steps-len(self.pred_to_plot), self.plt_time+self._time_steps), self.pred_to_plot)
            self.road_line.set_data(
                np.arange(self.plt_time+self._time_steps-len(self.pred_to_plot), self.plt_time+self._time_steps), self.road_ys_to_plot)
        self.fig.canvas.draw()
        self.fig.canvas.flush_events()
        plt.xlim((self.plt_time-600, self.plt_time+self._time_steps+10))
        plt.pause(0.0001)

    def append_data(self, pred, real):
        self.pred_to_plot += pred
        self.road_ys_to_plot += real


class RNN(object):

    def __init__(self, config, is_training):
        self._batch_size = config.batch_size
        self._time_steps = config.time_steps
        self._input_size = config.input_size
        self._output_size = config.output_size
        self._cell_size = config.cell_size
        self._is_training = config.is_training
        if not self._is_training:
            self._keep_prob = None
            self._lr = None
        else:
            self._keep_prob = config.keep_prob
            self._lr = config.learning_rate
        if not self._is_training:
            tf.reset_default_graph()
        self._built_RNN()
        self.saver = tf.train.Saver()
        self.sess = tf.Session()
        self.run(tf.initialize_all_variables())

    def _built_RNN(self):
        with tf.variable_scope('inputs'):
            self._xs = tf.placeholder(tf.float32, [self._batch_size, self._time_steps, self._input_size], name='xs')
            self._ys = tf.placeholder(tf.float32, [self._batch_size, self._time_steps, self._output_size], name='ys')
            self._is_initial = tf.placeholder(tf.bool, [self._batch_size, ], name='is_initial')

        with tf.variable_scope('input_layer'):
            l_in_x = tf.reshape(self.xs, [-1, self._input_size], name='2_2D')  # (batch*n_step, in_size)
            # Ws (in_size, cell_size)
            Wi = self._weight_variable([self._input_size, self._cell_size])
            # bs (cell_size, )
            bi = self._bias_variable([self._cell_size, ])
            # l_in_y = (batch * n_steps, cell_size)
            with tf.name_scope('Wx_plus_b'):
                l_in_y = tf.matmul(l_in_x, Wi) + bi
            with tf.name_scope('activation'):
                l_in_y = tf.nn.relu(l_in_y)
            # reshape l_in_y ==> (batch, n_steps, cell_size)
            l_in_y = tf.reshape(l_in_y, [-1, self._time_steps, self._cell_size], name='2_3D')

        with tf.variable_scope('lstm_cell'):
            lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(self._cell_size, forget_bias=1.0, state_is_tuple=True)
            if self._is_training and self._keep_prob < 1:
                lstm_cell = tf.nn.rnn_cell.DropoutWrapper(
                    lstm_cell, output_keep_prob=self._keep_prob)
            with tf.name_scope('initial_state'):
                self._cell_initial_state = lstm_cell.zero_state(self._batch_size, dtype=tf.float32)

            self.cell_outputs = []
            for t in range(self._time_steps):
                if not hasattr(self, 'cell_state'):
                    self.cell_output, self.cell_state = lstm_cell(l_in_y[:, t, :], self._cell_initial_state)
                else:
                    tf.get_variable_scope().reuse_variables()
                    self.cell_output, self.cell_state = lstm_cell(l_in_y[:, t, :], self.cell_state)
                self.cell_outputs.append(self.cell_output)
            self._cell_final_state = self.cell_state

        with tf.variable_scope('output_layer'):
            # cell_outputs_reshaped (BATCH*TIME_STEP, CELL_SIZE)
            cell_outputs_reshaped = tf.reshape(tf.concat(1, self.cell_outputs), [-1, self._cell_size])
            Wo = self._weight_variable((self._cell_size, self._output_size))
            bo = self._bias_variable((self._output_size,))
            self._pred = tf.matmul(cell_outputs_reshaped, Wo) + bo

        with tf.name_scope('cost'):
            # compute cost for the cell_outputs
            losses = tf.nn.seq2seq.sequence_loss_by_example(
                [tf.reshape(self._pred, [-1], name='reshape_pred')],
                [tf.reshape(self.ys, [-1], name='reshape_target')],
                [tf.ones([self._batch_size * self._time_steps], dtype=tf.float32)],
                average_across_timesteps=True,
                softmax_loss_function=self.ms_error,
                name='losses'
            )
            self._cost = tf.div(tf.reduce_sum(losses, name='losses_sum'), self._batch_size,
                          name='average_cost')

        if self._is_training:
            with tf.name_scope('trian'):
                self.train_op = tf.train.AdamOptimizer(self._lr).minimize(self._cost)

    @property
    def cell_initial_state(self):
        return self._cell_initial_state

    @property
    def cell_final_state(self):
        return self._cell_final_state

    @property
    def is_initial(self):
        return self._is_initial

    @property
    def xs(self):
        return self._xs

    @property
    def ys(self):
        return self._ys

    @property
    def pred(self):
        return self._pred

    @property
    def cost(self):
        return self._cost

    @staticmethod
    def ms_error(y_pre, y_target):
        return tf.square(tf.sub(y_pre, y_target))

    @staticmethod
    def _weight_variable(shape, name='weights'):
        initializer = tf.random_normal_initializer(mean=0., stddev=1., )
        return tf.get_variable(shape=shape, initializer=initializer, name=name)

    @staticmethod
    def _bias_variable(shape, name='biases'):
        initializer = tf.constant_initializer(0.1)
        return tf.get_variable(name=name, shape=shape, initializer=initializer)

    def run(self, *args, **kwargs):
        return self.sess.run(*args, **kwargs)

    def save(self, path):
        return self.saver.save(self.sess, path, write_meta_graph=False)

    def restore(self, path):
        self.saver.restore(self.sess, path)

    def predict(self, inputs, is_initial_state):
        if is_initial_state:
            self.state_ = self.run(self.cell_initial_state)
        feed_dict = {self._xs: inputs, self._cell_initial_state: self.state_}
        pred, self.state_ = self.run([self._pred, self._cell_final_state], feed_dict=feed_dict)
        return pred[0, 0]


class TrainConfig(object):
    data_path = 'datasets/I80-0400-0415-filter_0.8_T_v_ldxdvh.pickle'
    batch_size = 1
    time_steps = 20
    input_size = 4
    output_size = 1
    cell_size = 10
    is_training = True
    keep_prob = 1
    learning_rate = 0.0001


class TestConfig(object):
    data_path = 'datasets/I80-0400_lane2.pickle'
    batch_size = 1
    time_steps = 1
    input_size = 4
    output_size = 1
    cell_size = 10
    is_training = False
    restore_path = 'tmp/rnn'

if __name__ == '__main__':
    ITER_STEPS = 50000
    PLOT_LOOP = 500
    PREDICT = 'v'

    tf.set_random_seed(1)
    train_config = TrainConfig()
    # train(train_config, PREDICT)

    test_config = TestConfig()
    test(test_config, id=890, on_test=False, predict=PREDICT)